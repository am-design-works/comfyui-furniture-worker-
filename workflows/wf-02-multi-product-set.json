{
  "_meta": {
    "title": "WF-02: Multi-Product Set Compositing",
    "description": "Sequential placement of 2-4 products (desk + chair + storage) into a cohesive scene. Run this workflow once per product, using previous output as new background.",
    "version": "1.0.0",
    "author": "Amoeba AI Studio",
    "category": "furniture-compositing",
    "usage": "Step 1: Run with first product â†’ save output. Step 2: Use that output as scene_current.png, run with second product. Repeat for each product."
  },
  "10": {
    "inputs": {
      "image": "product_current.png"
    },
    "class_type": "LoadImage",
    "_meta": { "title": "Load Current Product (PNG with transparency)" }
  },
  "11": {
    "inputs": {
      "image": "scene_current.png"
    },
    "class_type": "LoadImage",
    "_meta": { "title": "Load Scene (original or previous composite)" }
  },
  "12": {
    "inputs": {
      "ckpt_name": "RealVisXL_V4.0.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": { "title": "Load SDXL Checkpoint" }
  },
  "13": {
    "inputs": {
      "ipadapter_file": "ip-adapter-plus_sdxl_vit-h.safetensors"
    },
    "class_type": "IPAdapterModelLoader",
    "_meta": { "title": "Load IP-Adapter" }
  },
  "14": {
    "inputs": {
      "clip_name": "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": { "title": "Load CLIP Vision" }
  },
  "15": {
    "inputs": {
      "control_net_name": "controlnet-depth-sdxl-1.0.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": { "title": "Load ControlNet Depth" }
  },
  "20": {
    "inputs": {
      "channel": "alpha",
      "image": ["10", 0]
    },
    "class_type": "ImageToMask",
    "_meta": { "title": "Extract Product Mask" }
  },
  "21": {
    "inputs": {
      "expand": 6,
      "blur": 3,
      "mask": ["20", 0]
    },
    "class_type": "GrowMask",
    "_meta": { "title": "Expand Mask for Blending" }
  },
  "22": {
    "inputs": {
      "image": ["11", 0]
    },
    "class_type": "MiDaS-DepthMapPreprocessor",
    "_meta": { "title": "Depth Map from Current Scene" }
  },
  "24": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": 0.35,
      "image": ["10", 0]
    },
    "class_type": "ImageScaleBy",
    "_meta": { "title": "Scale Product (adjust scale_by: 0.2-0.6)" }
  },
  "25": {
    "inputs": {
      "x": 400,
      "y": 550,
      "resize_source": false,
      "destination": ["11", 0],
      "source": ["24", 0],
      "mask": ["20", 0]
    },
    "class_type": "ImageCompositeMasked",
    "_meta": { "title": "Position Product (adjust x, y for each product)" }
  },
  "26": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": 0.35,
      "image": ["21", 0]
    },
    "class_type": "ImageScaleBy",
    "_meta": { "title": "Scale Mask to Match Product" }
  },
  "30": {
    "inputs": {
      "weight": 0.75,
      "weight_type": "linear",
      "combine_embeds": "concat",
      "start_at": 0.0,
      "end_at": 0.85,
      "embeds_scaling": "V only",
      "model": ["12", 0],
      "ipadapter": ["13", 0],
      "image": ["10", 0],
      "clip_vision": ["14", 0]
    },
    "class_type": "IPAdapterAdvanced",
    "_meta": { "title": "IP-Adapter (current product identity)" }
  },
  "31": {
    "inputs": {
      "strength": 0.5,
      "start_percent": 0.0,
      "end_percent": 0.8,
      "positive": ["40", 0],
      "negative": ["41", 0],
      "control_net": ["15", 0],
      "image": ["22", 0]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": { "title": "Apply ControlNet Depth" }
  },
  "40": {
    "inputs": {
      "text": "cohesive interior scene, multiple furniture pieces, consistent lighting, professional showroom photography, natural daylight, soft shadows, modern office design, architectural quality, 8k, sharp",
      "clip": ["12", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": { "title": "Positive Prompt (multi-product scene)" }
  },
  "41": {
    "inputs": {
      "text": "inconsistent lighting, mismatched shadows, floating furniture, warped, distorted, duplicate products, blurry, low quality, cartoon, unrealistic scale",
      "clip": ["12", 1]
    },
    "class_type": "CLIPTextEncode",
    "_meta": { "title": "Negative Prompt" }
  },
  "51": {
    "inputs": {
      "grow_mask_by": 10,
      "pixels": ["25", 0],
      "vae": ["12", 2],
      "mask": ["26", 0]
    },
    "class_type": "VAEEncodeForInpaint",
    "_meta": { "title": "Encode for Inpainting" }
  },
  "60": {
    "inputs": {
      "seed": 42,
      "steps": 28,
      "cfg": 6.5,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.5,
      "model": ["30", 0],
      "positive": ["31", 0],
      "negative": ["31", 1],
      "latent_image": ["51", 0]
    },
    "class_type": "KSampler",
    "_meta": { "title": "KSampler (lower denoise to preserve existing products)" }
  },
  "70": {
    "inputs": {
      "samples": ["60", 0],
      "vae": ["12", 2]
    },
    "class_type": "VAEDecode",
    "_meta": { "title": "VAE Decode" }
  },
  "90": {
    "inputs": {
      "filename_prefix": "multiproduct_step",
      "images": ["70", 0]
    },
    "class_type": "SaveImage",
    "_meta": { "title": "Save Intermediate (use as next scene_current.png)" }
  },
  "100": {
    "inputs": {
      "text": "WORKFLOW USAGE:\n1. First run: Set scene_current.png to base scene, product_current.png to first product (e.g., desk)\n2. Adjust x, y position and scale_by for proper placement\n3. Save output as new scene_current.png\n4. Second run: Load chair as product_current.png, adjust position\n5. Repeat for each additional product\n\nPOSITION GUIDE:\n- Desk: x=350, y=450, scale=0.45\n- Chair: x=550, y=600, scale=0.35\n- Storage: x=800, y=400, scale=0.30\n\nAdjust based on scene layout."
    },
    "class_type": "Note",
    "_meta": { "title": "Usage Instructions" }
  }
}
